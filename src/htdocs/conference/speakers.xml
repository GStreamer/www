<?xml version="1.0"?>
<!DOCTYPE xml
[
  <!ENTITY % site-entities SYSTEM "../entities.site">
    %site-entities;
    ]>

<?xml-stylesheet href="../page.xsl" type="text/xsl"?>
<page>
  <title>GStreamer Conference 2012 Program </title>

<body lang="en-US" dir="LTR">

<h1>Speakers bio and abstracts - GStreamer Conference 2012</h1>
<h2>San Diego, USA, August 27th and August 28th, 2012</h2>
<p><a href="http://gstreamer.freedesktop.org/conference">Back to conference main page</a></p>
<p><a href="http://gstreamer.freedesktop.org/conference/gstreamer-conference-timetable.html">Back to conference timetable</a></p>
<table width="100%" border="1" bordercolor="#C0C0C0" cellpadding="4" cellspacing="2">
	
	<tr valign="top" bgcolor="#C0C0C0"><td>
	<a name="taymans" id="taymans"></a>
	<p><b>Keynote - GStreamer 1.0, Wim Taymans, Collabora</b></p>
	<p>
	Wim Taymans is one of the founders of the GStreamer project and the man behind the current GStreamer design. Wim has a long history in the development of multimedia software, starting with computer game development on the Commodore 64. Wim Taymans and is working on assisting Collabora customers with the design and use of GStreamer.
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
	The GStreamer 1.0 release will be out before this years GStreamer Conference and this talk will provide a final summary of the changes and improvements GStreamer 1.0. The talk will also outline the plans for the 1.0 series going forward.</p>
	</i>	
	</td></tr>

	<tr valign="top"><td>
	<a name="hoegsberg" id="hoegsberg"></a>
	<p><b>Wayland development and plans, Kristian Hoegsberg, Intel</b></p>
	<p>Kristian has worked on X and Linux Graphics in general since 2004 and helped make AIGLX and DRI2 happen. Recently he’s been working on the Wayland display server. Kristian currently works at Intel, doing Linux graphics stack development.
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
TBD
	</p>
	</i>
	</td></tr>

	<tr valign="top" bgcolor="#C0C0C0"><td>
	<a name="verkuil" id="verkuil"></a>
	<p><b>Video4Linux: Current Status and Future Work, Hans Verkuil, Cisco</b></p>
	<p>
	Hans Verkuil started contributing patches to the MPEG encoder/decoder ivtv driver
in early 2004 and it snowballed from there. Since 2008 he works on a new video4linux
core framework with the goal of fully supporting complex embedded video hardware. He
lives in Oslo, Norway, working as a senior R&amp;D software engineer at Cisco Systems Norway,
developing both Linux and NIOS-based drivers. He gave V4L presentations before during
Embedded Linux Conferences in the US and Europe, the Plumbers Conference and LinuxCon
in Japan..</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
Video4Linux is a fast-changing subsystem where a lot of work is done to support
the complex video hardware of embedded systems. This presentation will give an
overview of recent developments and the work that is planned for the near future.
	</p>
	</i>

	</td></tr>
	
	<tr valign="top"><td>
	<a name="burks" id="burks"></a>
	<p><b>GStreamer for advanced image capture and analysis - Stephen Burks, U.S Army</b></p>
	<p>TBD
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
At NVESD we work with imaging sensors and often have a need to capture, process, analyze, and transmit information from them. We have found that GStreamer is well suited for solving many of our requirements. These include capturing uncompressed video from sources such as Camera Link frame grabbers, tagging frames with highly accurate timestamps, and associating frames with other metadata such as sensor readings and GPS/IMU data. We are also working on the use of the Material Exchange Format (MXF) for storing uncompressed video along with metadata with the goal of standardization by the Motion Imagery Standards Board (MISB). As part of this effort we are implementing support for SMPTE 336M KLV metadata in pipelines. Stephen Burks will discuss our motivations and approach.
	</p>
	</i>
	</td></tr>
		
	<tr bgcolor="#C0C0C0"><td>
	<a name="jaquez" id="jaquez"></a>
        <p><b>Development of hardware-based Elements for GStreamer 1.0: A case study, Victor Jaquez</b></p>
	<p>
Víctor worked for TI, in Mexico, in the development of GStreamer elements for the OMAP3 processors. At Igalia he has been involved in several projects for OMAP3 and OMAP4 processors.
	</p>

	<i>
	<p><b>Talk Abstract</b></p>
	<p>
GStreamer 1.0 brings new features for memory handling, particularly the
management of buffers. Now it is possible to implement elements that make use
of memory areas that are not accessed directly by CPU, such as the video
memory, continuous memory areas and so on.</p>
<p>
The purpose of this talk is to show how we can use these new interfaces for
developing GStreamer elements, that are tightly integrated with the
hardware. In particular, we will show how we implemented a simple video sink
for the pandaboard, using the Direct Rendering Management (DRM) interface.
</p><p>
This element, called kmssink, uses many of the new concepts for memory
handling, added in GStreamer v1.0, such as allocators, buffer pools, and so
on. We will review these concepts and how they were used in the element.
	</p>
	</i>

	</td></tr>

	<tr valign="top"><td>
	<a name="morales" id="morales"></a>
	<p><b>The GStreamer SDK - Andoni Morales, Fluendo</b></p>
	<p>TBD</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
On February 2012, Fluendo and Collabora announced a partnership to
create a Software Development Kit for GStreamer, with the objective of
providing a tested and stable version of GStreamer, with a full
development environment to build GStreamer applications in the 3 most
important operating systems: Linux, Mac OS X and Windows.
</p><p>
The main goal of this SDK is to break the walls of GStreamer's
development in platforms like OS X and Windows, where building and
deploying GStreamer wasn't straightforward, providing native installer
packages with precompiled binaries, development files and integration
with IDE's like Visual Studio and XCode as well as a complete
documentation with tutorials and instructions to use the SDK in all
the platforms.
</p><p>
In this talk I will present the decisions made to create the GStreamer
SDK for all the target platforms, such as the GStreamer components
selected for the first version of the SDK, the GUI toolkits included
to develop graphical applications, the way we achieved  modularization
and versioning of the SDK and the packaging tools used to distribute
it.
</p><p>
I will also present cerbero, the multi-platform build system created
to build and package the SDK, showing how it can be used to compile
GStreamer and other projects for different platforms, architectures
and distributions. I will finish talking about the several problems
encountered while developing the SDK in all the platforms and
architectures, trying to show the hard process of getting a
cross-platform distribution of GStreamer and why this SDK was needed
to make our loved GStreamer the best option for cross-platform
multimedia development!</p>
	</i>
	</td></tr>

	<tr bgcolor="#C0C0C0"><td>
	<a name="hervey" id="hervey"></a>
	<p><b>CPU, Memory, Latency: Profiling and Optimizing GStreamer - Edward Hervey, Collabora</b></p>
	<p>
Edward Hervey has been contributing to FOSS projects, and the
GStreamer multimedia framework in particular, since 2003 when he
initiated the PiTiVi video editor project. Since then, he has become a
core contributor to GStreamer and contributes mainly to extending it
to new use-cases, improving its performance and integration on
numerous platforms and systems. Hervey has been giving presentations
on those multiple usages of GStreamer since 2005. Hervey is a Senior
Multimedia Architect at Collabora where he helps clients and
decision-makers into making the most of the GStreamer framework and
other FOSS technologies Collabora creates and maintains. 
</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
While GStreamer already achieves very good performance on various
platforms, architectures and use-cases, there is still room for
improvement. What satisfies one use-case might not be sufficient for
another use-case. Bottlenecks that were not noticeable on a desktop
computer becomes a show-stopper on an embedded platform. Latency that
was not impacting local file playback can make real-time communication
impossible even on a powerful machine.
</p><p>
During this talk Edward Hervey will first go through the various
metrics one wants to track: cpu usage, memory usage and latency being
the main ones. He will expose how they impact the various use-cases,
and how they are tied together.
</p><p>
The hardest part of optimization is actually identifying and
understanding where the bottleneck or issue lies. Therefore in a
second part, Hervey will go over the available methodologies and tools
one can use to profile the various metrics. This will range from those
applicable to any project, to those specific to GStreamer. The goal of
this second part is to pinpoint what our bottleneck or issues are, how
to avoid false-positives and the limitations and advantages of each
profiling technique.
</p><p>
Various examples of past and current optimizations will be shown, how
they were identified and solved. This will include tools and scripts
that were created for that purpose.
</p><p>
While this talk is mostly aimed at developers using GStreamer, it
should also prove interesting to other developers, as well as
general public wanting to understand profiling and optimization.
</p>
	</i>
	</td></tr>
	
	<tr valign="top"><td>
	<a name="schleef" id="schleef"></a>
	<p><b>GStreamer Streaming library - David Schleef, Entropy Wave</b></p>
	<p>
	David Schleef is the founder and CEO of Entropy Wave, a San Francisco based company providing products and services that enable its customers to use open video technology such as WebM and Ogg/Theora for archival, professional editing, broadcasting, and content distribution. David has been an active member in the open source community for 15 years, working most recently on projects such as GStreamer, a cross-platform multimedia framework, the Dirac video codec, and various Xiph.org projects.
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
TBD
	</p>
	</i>
	</td></tr>
		
	<tr bgcolor="#C0C0C0"><td>
	<a name="verdejo" id="verdejo"></a>
	<p><b>Current status of the Android enablement - Reynaldo Verdejo, Collabora</b></p>
	<p>
I'm a Software Developer working for Collabora for the past 4 years. I've worked mostly as a VoIP/Streaming expert on various technologies like GStreamer and Farsight. I'm the maintainer of libnice, a NAT-Traversal library implementing the ICE specification. In my free time, I'm the project leader of the aMSN Messenger client, as well as founder of the PSFreedom, PL3 and PS3MFW projects.
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
Our GStreamer on Android port has made quite a lot of
progress since last year. So has Android itself. How have
we worked around latest platform changes? What's the
status of the NDK port. What about replacing stagefright
on Ice Cream Sandwich? What are we working on right now?
How can you help?
</p><p>
Idea of the talk is to present a detailed sum up of the work
made on enabling GStreamer on Android during last year.
To both sync with people working with GStreamer on
this platform and hopefully gather some community
interest and contributions.
	</p>
	</i>
	</td></tr>
	
	<tr valign="top"><td>
	<a name="derose" id="derose"></a>
	<p><b>Improving GStreamer quality - Jason Gerard DeRose, Novacut</b></p>
	<p>
Jason is the lead developer of the Novacut collaborative video editor. In the past he was working at Red Hat as part of the FreeIPA team. Most of Jason's career has been working with web technologies (both sever and client side), but he's had a longtime love affair with GStreamer. Worlds do collide.</p>
<i>
	<p><b>Talk Abstract</b></p>
	<p>
Pro video requires impeccable reliability, release after release. To prevent regressions, we need a practical way to do continuous integration testing against a rather exhaustive set of real-world video files. We also need to test extensive NLE scenarios with video files from professional cameras. And to make life easy for developers, we need the feedback loop to be as fast as possible.
</p><p>
Novacut is building a GStreamer-based testing tool to do just this, and we're harnessing the cloud to get the compute resources needed run such tests in a sane amount of time (and also not break the bank).
	</p>
	</i>
	</td></tr>
	
	<tr bgcolor="#C0C0C0"><td>
	<a name="muller" id="muller"></a>
	<p><b>GStreamer Status Report, Tim-Philipp Müller, Collabora</b></p>
	<p>
Tim-Philipp Müller is a GStreamer developer and maintainer. He studied in Hamburg, York and Aberystwyth before going to work for Fluendo. He co-founded Collabora Multimedia in 2007 and currently lives in Bristol, UK.

	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
While GStreamer 1.0 looms close on the horizon a lot of development is still happening in the 0.10 branch, most of which will migrate accross to 10. Tim-Philipp Müller is the maintainer and release manager for GStreamer 0.10.x. This talk will give you a whirlwind tour of what's new and improved in and around GStreamer over the course of the last year.
</p><p>
The talk includes a high-level overview of all kinds of cool things we've improved and done lately, especially. from an application developer perspective. Topics will range from things like AC-3 passthrough now working, va-api support and transcoding improvements. The talk will also talk a bit about the support plans for GStreamer 0.10.x once GStreamer 1.0 has been released.
	</p>
	</i>
	</td></tr>
	
	<tr valign="top"><td>
	<a name="cannon" id="cannon"></a>
	<p><b>GStreamer for Large-Scale Scientific Signal Processing - Victories and
Wish-lists - Kipp Cannon, CITA</b></p>
	<p>
Kipp Cannon is a senior research associate at the Canadian Institute for Theoretical Astrophysics in Toronto.  He received his doctorate in physics from the University of Alberta, Edmonton, in the field of early universe cosmology, and ahs worked at the University of Wisconsin-Milwaukee and then at the California Institute of Technology before moving home to Toronto where he uses GStreamer to search for waves of gravity from colliding back holes.
</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
Gravitational waves are waves of spacetime curvature generated by the
movement of masses.  They are a prediction of the general theory of
relativity, and although their existence has been inferred they have never
been directly detected.  In the last decade, a world-wide network of
gravitational-wave detectors has been developed with the goal of
establishing the first direct observation of gravitational waves from the
most extreme events in the universe such as the collisions of black holes
and neutron stars.  Rapid detection and localization of gravitational waves
will allow gravitational-wave detectors to be part of a larger transient
astronomy community and will provide exciting, new information about our
Universe.</p>
<p>
Gravitational-wave detection presents significant signal processing
challenges, and we have used GStreamer to address many of them.  We
regularly run GStreamer applications having hundreds of processes with
thousands of threads per process spanning tens of thousands of CPU cores.
Our experience scaling GStreamer up to this level has been remarkably
painless, thanks in large part to the GStreamer community.  In this talk,
we'll discuss our experiences, and present some of our own wish-list items
for future GStreamer development.
	</p>
	</i>
	</td></tr>
	
	<tr valign="top" bgcolor="#C0C0C0"><td>
	<a name="clark" id="clark"></a>
	<p><b>GStreamer, dmabuf, and OMAP4+ Update - Rob Clark, Texas Instruments</b></p>
	<p>
Rob Clark has been working in the arm embedded world for more than 10
years, and playing with linux for even longer. These days mostly
working on the graphics end of things (omapdrm, xf86-video-omap) and
more optimal integration of graphics and multimedia (dmabuf,
dri2video).</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
An update of GStreamer on TI OMAP4+ platforms.  In the last year, a
new mechanism called dmabuf has been developed at the kernel/driver
level for zero copy buffer sharing between different devices (video
codecs, gpu and display, camera, etc).  Compared to how things worked
2 years ago when the OMAP+GStreamer architecture was last presented,
this dmabuf based architecture allows for more commonality between x86
and various other ARM platforms, while at the same time providing
greater flexibility.  And it is based on infrastructure that is part
of the upstream linux kernel rather than custom TI mechanisms.  We
will cover how we've added support for this in GStreamer 0.10 and how
it fits in to GStreamer 1.0, as well as what is still missing.
	</p>
	</i>
	</td></tr>
	
	<tr><td>
	<a name="emont" id="emont"></a>
	<p><b>Playing in the sandbox - GStreamer security - Guillame Emont, Igalia</b></p>
        <p>
Guillaume Emont has been playing around on various things related to multimedia (Elisa/Moovida, Pigment, Grilo and of course GStreamer) in the Free software world for a few years and enjoys it a lot. He is now proudly part of the awesome group of hackers known as Igalia.
</p><p>
When he doesn't hack on software, he enjoys discussing with like-minded people around a drink or a good meal, various outdoor sports in and around sunny Barcelona, or trying to take photos from above using helium balloons, among many other things.
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
GStreamer is a big and successful project that implements complex
formats. We use it to read media streams that sometimes come from
untrusted sources.
</p><p>
The size and complexity of GStreamer and all the format implementations
it brings means that the presence of security bugs in a media playback
pipeline is not totally unlikely. An attacker could forge a stream that
would exploit such a bug so that he can execute code of his making in
the context where the exploited code was running.
</p><p>
A common way to alleviate this kind of issue is to run the software
handling untrusted data in a context where its privileges are very
limited, so that a successful exploit of a bug in the software would
only grant the attacker execution rights in that limited context. We
call such a context a sandbox.
</p><p>
I have run some experiments[1] with setuid-sandbox[2], a stand-alone
version of the sandboxing system used by chrome on GNU/Linux, that shows
the feasibility of running at least part of a pipeline in a sandbox. In
this talk, I will explain this work[3], its limitations and discuss what
can be done to improve on it.
	</p>
	</i>
	</td></tr>
	
	<tr valign="top" bgcolor="#C0C0C0"><td>
	<a name="schmidt" id="schmidt"></a>
	<p><b>GStreamer and multi-room playout, Jan Schmidt, Oracle</b></p>
	<p>
Jan is a GStreamer maintainer and primary author of DVD playback support, among other things. In the past he worked for Fluendo and Sun Microsystems. Currently, he lives in Albury Australia, working from home for Oracle Corporation, and hacks on GStreamer as he can.
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
This talk will look at an implementation of a multi-room entertainment
system - allowing synchronised playback of music or movies in multiple
rooms simultaneously. Commercial implementations of such systems
(squeezebox, Sonos) can be costly - but the basic mechanism is quite
simple.
	</p>
	</i>
	</td></tr>
		
	<tr><td>
	<p><b>Development with GES, Jeff Fortin, Collabora</b></p>
	<a name="fortin" id="fortin"></a>
	<p>TBD
	</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
TBD
	</p>
	</i>
	</td></tr>
	
	<tr valign="top" bgcolor="#C0C0C0"><td>
	<a name="iwai" id="iwai"></a>
	<p><b>ALSA project status update - Takashi Iwai, Suse</b></p>
	<p>
TBD.</p>

	<i>
	<p><b>Talk Abstract</b></p>
	<p>
TBD
	</p>
	</i>
	</td></tr>
	
	<tr valign="top"><td>
	<a name="droege" id="droege"></a>
	<p><b>GStreamer base classes – or how to make your life easier - Sebastian Dröge</b></p>
	<p> Sebastian Dröge is working on GStreamer since early 2006 and nowadays is one of the main developers. He also works on other open source  projects in his free time and is working for Collabora on GStreamer and related technologies since 2008. Sebastian has a master's degree in computer sciences.</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
GStreamer provides base class for many common element types, including
just recently added base classes for audio/video decoders and encoders.
People often ask, if it is a good idea to use a base class for this or
that problem and which base class they should use.
This talk will introduce them, explains what they're doing and when they
should be used, describes the concepts and how they are used and what
advantages of their use is. In the end some future ideas for base classes and improvements to the
existing base classes will be discussed.
	</p>
	</i>
	</td></tr>

	<tr valign="top"><td>
	<a name="staedler" id="staedler"></a>
	<p><b>Debugging GStreamer pipelines, Rene Staedler, Collabora</b></p>
	<p>
TDB
</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>TBD</p></i>

	</td></tr>

	<tr valign="top"><td>
	<a name="terriberry" id="terriberry"></a>
	<p><b>The Opus Audio Codec, Timothy B. Terriberry,  Xiph.org</b></p>
	<p>TBD</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
TBD
	</p>
	</i>
	</td></tr>

	<tr valign="top"><td>
	<a name="anholt" id="anholt"></a>
	<p><b>OpenGL and Mesa development - Eric Anholt, Intel </b></p>
	<p>TBD
</p>
	<i>
	<p><b>Talk Abstract</b></p>
	<p>
TBD
	</p>
	</i>
	</td></tr>


</table>

</body>
</page>
